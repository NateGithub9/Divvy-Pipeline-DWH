{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1bf0b1e-bd17-403f-aa30-5adc2dda2cd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE silver_trip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a5c779e-8bde-452d-b5f7-64b95a4b2c42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--first part of silver transformation (CTE inside A CTAS, distance and minutes calculations) --> silver_trip_data\n",
    "CREATE TABLE silver_trip_data\n",
    "USING DELTA\n",
    "AS\n",
    "WITH T1 AS (\n",
    "    SELECT\n",
    "        ride_id,\n",
    "        rideable_type,\n",
    "        member_casual,\n",
    "        start_lat,\n",
    "        start_lng,\n",
    "        end_lat,\n",
    "        end_lng,\n",
    "        CAST(started_at AS TIMESTAMP) AS trip_start_ts,\n",
    "        CAST(ended_at AS TIMESTAMP) AS trip_end_ts,\n",
    "        COALESCE(start_station_name, 'N/A') AS start_station_name,\n",
    "        COALESCE(start_station_id, 'N/A') AS start_station_id,\n",
    "        COALESCE(end_station_name, 'N/A') AS end_station_name,\n",
    "        COALESCE(end_station_id, 'N/A') AS end_station_id\n",
    "    FROM\n",
    "        divvy.default.bronze_trip_data\n",
    "    WHERE \n",
    "        _rescued_data IS NULL\n",
    "        AND started_at IS NOT NULL\n",
    "        AND ended_at IS NOT NULL\n",
    "),\n",
    "\n",
    "Calculated AS (\n",
    "    SELECT\n",
    "        *, \n",
    "        CASE\n",
    "            WHEN trip_end_ts > trip_start_ts\n",
    "            THEN ROUND(TIMESTAMPDIFF(SECOND, trip_start_ts, trip_end_ts) / 60.0, 2)\n",
    "            ELSE NULL\n",
    "        END AS Trip_Duration_Min,\n",
    "        ROUND(\n",
    "            6371 * 2 * ASIN(\n",
    "                SQRT(\n",
    "                    POW(SIN(RADIANS(end_lat - start_lat) / 2), 2) +\n",
    "                    COS(RADIANS(start_lat)) * COS(RADIANS(end_lat)) *\n",
    "                    POW(SIN(RADIANS(end_lng - start_lng) / 2), 2)\n",
    "                )\n",
    "            ),\n",
    "            2\n",
    "        ) AS Trip_Distance_Km,\n",
    "        CAST(trip_start_ts AS DATE) AS Full_Date\n",
    "    FROM\n",
    "        T1\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    T2.trip_start_ts,\n",
    "    T2.trip_end_ts,\n",
    "    T2.start_station_name,\n",
    "    T2.ride_id,\n",
    "    T2.rideable_type,\n",
    "    T2.member_casual,\n",
    "    T2.Full_Date,\n",
    "    T2.start_station_id,\n",
    "    T2.end_station_id,\n",
    "    T2.Trip_Duration_Min,\n",
    "    T2.Trip_Distance_Km,\n",
    "    T2.start_lat,\n",
    "    T2.start_lng,\n",
    "    T2.end_lat,\n",
    "    T2.end_lng\n",
    "FROM\n",
    "    Calculated AS T2\n",
    "WHERE\n",
    "    T2.Trip_Distance_Km > 0.05\n",
    "    AND T2.Trip_Duration_Min IS NOT NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "156339dd-62d3-4abb-b928-dcd24344b9f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- silver_trip_data_pk\n",
    "ALTER TABLE silver_trip_data\n",
    "ALTER COLUMN ride_id SET NOT NULL;\n",
    "\n",
    "ALTER TABLE silver_trip_data\n",
    "ADD CONSTRAINT silver_trip_data_pk PRIMARY KEY (ride_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a0b1ece-1bbc-4f50-b5ea-91dc5526fbb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Silver Weather Data Transformation\n",
    "\n",
    "CREATE OR REPLACE TABLE silver_weather_data\n",
    "USING DELTA\n",
    "AS\n",
    "SELECT\n",
    "    to_timestamp(\n",
    "        concat(\n",
    "            CAST(YEAR AS STRING), '-',\n",
    "            lpad(CAST(MO AS STRING), 2, '0'), '-',\n",
    "            lpad(CAST(DY AS STRING), 2, '0'), ' ',\n",
    "            lpad(CAST(HR AS STRING), 2, '0'), ':00:00' \n",
    "        ),\n",
    "        'yyyy-MM-dd HH:mm:ss'\n",
    "    ) AS weather_ts,\n",
    "    \n",
    "    concat(YEAR, lpad(MO, 2, '0'), lpad(DY, 2, '0'), lpad(HR, 2, '0')) AS silver_weather_data_pk,\n",
    "\n",
    "    CAST(TEMP AS DOUBLE) AS temp_celsius,\n",
    "    CAST(PRCP AS DOUBLE) AS prcp_mm,\n",
    "    CAST(HMDT AS DOUBLE) AS hmdt_percent,\n",
    "    CAST(WND_SPD AS DOUBLE) AS wnd_spd_kph,\n",
    "    CAST(ATM_PRESS AS DOUBLE) AS atm_press_hpa,\n",
    "    CAST(\n",
    "        concat(\n",
    "            CAST(YEAR AS STRING),\n",
    "            lpad(CAST(MO AS STRING), 2, '0'),\n",
    "            lpad(CAST(DY AS STRING), 2, '0')\n",
    "        ) AS INT\n",
    "    ) AS Date_Key\n",
    "    \n",
    "FROM\n",
    "    divvy.default.bronze_weather_data\n",
    "    \n",
    "WHERE\n",
    "    _rescued_data IS NULL   \n",
    "    AND YEAR IS NOT NULL           \n",
    "    AND TEMP IS NOT NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae69096c-3fcc-4bdd-8947-8348b27f4be4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- silver_weather_data_pk\n",
    "\n",
    "ALTER TABLE silver_weather_data\n",
    "ALTER COLUMN silver_weather_data_pk SET NOT NULL;\n",
    "\n",
    "ALTER TABLE silver_weather_data\n",
    "ADD CONSTRAINT silver_weather_data_pk PRIMARY KEY (silver_weather_data_pk)\n",
    "NOT ENFORCED;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38f60707-80ad-4487-9958-dc1753b5aa57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# GEOLOCALISATION ENRICHMENT SCRIPT \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, h3_longlatash3, lit, monotonically_increasing_id\n",
    "\n",
    "# --- Configuration ---\n",
    "H3_RESOLUTION = 10\n",
    "TRIP_DATA_SOURCE_TABLE = \"bronze_trip_data\" \n",
    "COMMUNITY_H3_TABLE = \"dim_community_h3_index\"\n",
    "TARGET_DIM_TABLE = \"gold.Dim_Station_Final\" \n",
    "\n",
    "# --- 1. Union and Deduplicate All Station Points ---\n",
    "\n",
    "df_trip = spark.table(TRIP_DATA_SOURCE_TABLE)\n",
    "\n",
    "# 1a. Select all START stations\n",
    "df_start_stations = df_trip.select(\n",
    "    col(\"start_station_name\").alias(\"Station_Name\"),\n",
    "    col(\"start_lat\").alias(\"Latitude\"),\n",
    "    col(\"start_lng\").alias(\"Longitude\")\n",
    ").filter(col(\"start_lat\").isNotNull() & col(\"start_lng\").isNotNull())\n",
    "\n",
    "# 1b. Select all END stations\n",
    "df_end_stations = df_trip.select(\n",
    "    col(\"end_station_name\").alias(\"Station_Name\"),\n",
    "    col(\"end_lat\").alias(\"Latitude\"),\n",
    "    col(\"end_lng\").alias(\"Longitude\")\n",
    ").filter(col(\"end_lat\").isNotNull() & col(\"end_lng\").isNotNull())\n",
    "\n",
    "# 1c. Combine and deduplicate\n",
    "df_station_base = df_start_stations.union(df_end_stations).distinct()\n",
    "df_station_base.cache() # Cache the base for efficiency\n",
    "\n",
    "print(f\"âœ… Extracted {df_station_base.count()} unique station records from trip data.\")\n",
    "\n",
    "# --- 2. Calculate H3 Index and Prepare for Join ---\n",
    "\n",
    "# Calculate the H3 Index for each station point\n",
    "# NOTE: h3_longlatash3 requires Longitude, then Latitude!\n",
    "df_station_indexed = df_station_base.withColumn(\n",
    "    \"h3_index_10\",\n",
    "    h3_longlatash3(col(\"Longitude\"), col(\"Latitude\"), lit(H3_RESOLUTION))\n",
    ").filter(col(\"h3_index_10\").isNotNull()) \n",
    "\n",
    "# Load the H3 cell -> Community Name mapping table\n",
    "df_community_h3 = spark.table(COMMUNITY_H3_TABLE).select(\n",
    "    col(\"h3_index_10\").alias(\"c_h3_index\"),\n",
    "    col(\"community\").alias(\"neighborhood_name\")\n",
    ")\n",
    "\n",
    "# --- 3. Perform the H3-Based Spatial Join and Final Select ---\n",
    "\n",
    "df_station_enriched = df_station_indexed.join(\n",
    "    df_community_h3,\n",
    "    df_station_indexed[\"h3_index_10\"] == df_community_h3[\"c_h3_index\"],\n",
    "    \"left\"\n",
    ").withColumn(\n",
    "    # Generate the surrogate key for the dimension table\n",
    "    \"Station_Key\", monotonically_increasing_id()\n",
    ").select(\n",
    "    \"Station_Key\", \n",
    "    col(\"Station_Name\"),\n",
    "    col(\"Latitude\"),\n",
    "    col(\"Longitude\"),\n",
    "    col(\"h3_index_10\"),\n",
    "    col(\"neighborhood_name\"),\n",
    "    (col(\"neighborhood_name\").isNotNull()).alias(\"is_in_community_area\")\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Station-Community Join Complete. Schema of final dim table:\")\n",
    "df_station_enriched.printSchema()\n",
    "\n",
    "# --- 4. Write to the Final Delta Table (Gold Layer) ---\n",
    "\n",
    "(df_station_enriched.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"overwriteSchema\", \"true\")\n",
    "  .saveAsTable(TARGET_DIM_TABLE)\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸš€ Successfully wrote enriched dimension table to: {TARGET_DIM_TABLE}\")\n",
    "\n",
    "# --- 5. Optimization (Mandatory for Spatial Queries) ---\n",
    "\n",
    "spark.sql(f\"OPTIMIZE {TARGET_DIM_TABLE} ZORDER BY (h3_index_10)\")\n",
    "\n",
    "print(\"\\nâœ¨ Z-Ordering complete on h3_index_10 for optimal query performance.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4811261326724904,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03 - Transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
