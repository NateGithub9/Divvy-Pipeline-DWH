{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f846ea8-4bd6-483f-8344-d0acbb46ebcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#DIM DATE DAY TABLE\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, date_format, year, quarter, month, dayofmonth, dayofweek, \n",
    "    when, lit, expr\n",
    ")\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, BooleanType\n",
    "\n",
    "# Define date range\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2030-12-31\"\n",
    "\n",
    "# Create a DataFrame with a sequence of dates\n",
    "dates_df = spark.sql(f\"\"\"\n",
    "  SELECT sequence(to_date('{start_date}'), to_date('{end_date}'), interval 1 day) as date_seq\n",
    "\"\"\").selectExpr(\"explode(date_seq) as Full_Date\")\n",
    "\n",
    "# Add columns\n",
    "dim_date_df = dates_df \\\n",
    "    .withColumn(\"Date_Key\", date_format(col(\"Full_Date\"), \"yyyyMMdd\").cast(IntegerType())) \\\n",
    "    .withColumn(\"Year\", year(col(\"Full_Date\"))) \\\n",
    "    .withColumn(\"Quarter\", quarter(col(\"Full_Date\"))) \\\n",
    "    .withColumn(\"Month\", month(col(\"Full_Date\"))) \\\n",
    "    .withColumn(\"Month_Name\", date_format(col(\"Full_Date\"), \"MMMM\")) \\\n",
    "    .withColumn(\"Day_of_Month\", dayofmonth(col(\"Full_Date\"))) \\\n",
    "    .withColumn(\"Day_of_Week\", dayofweek(col(\"Full_Date\"))) \\\n",
    "    .withColumn(\"Day_Name\", date_format(col(\"Full_Date\"), \"EEEE\")) \\\n",
    "    .withColumn(\"Is_Weekend\", when(col(\"Day_of_Week\").isin([1,7]), lit(True)).otherwise(lit(False))) \\\n",
    "    .withColumn(\n",
    "        \"Season\",\n",
    "        when(month(col(\"Full_Date\")).isin([12,1,2]), \"Winter\")\n",
    "        .when(month(col(\"Full_Date\")).isin([3,4,5]), \"Spring\")\n",
    "        .when(month(col(\"Full_Date\")).isin([6,7,8]), \"Summer\")\n",
    "        .otherwise(\"Fall\")\n",
    "    )\n",
    "\n",
    "# Reorder columns\n",
    "dim_date_df = dim_date_df.select(\n",
    "    \"Date_Key\", \"Full_Date\", \"Year\", \"Quarter\", \"Month\", \"Month_Name\",\n",
    "    \"Day_of_Month\", \"Day_of_Week\", \"Day_Name\", \"Is_Weekend\", \"Season\"\n",
    ")\n",
    "\n",
    "# Create managed table\n",
    "dim_date_df.write.mode(\"overwrite\").saveAsTable(\"divvy.default.DIM_Date_day\")\n",
    "\n",
    "display(dim_date_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26edfabd-88ee-404a-baf3-2412515811f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- PK for dim_date_day\n",
    "ALTER TABLE divvy.default.DIM_Date_day\n",
    "ADD CONSTRAINT dim_date_day_pk PRIMARY KEY (Date_Key)\n",
    "NOT ENFORCED;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9adfd646-f21c-4cd1-8a7a-7a0acaa4e190",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#DIM DATE HOUR TABLE\n",
    "\n",
    "from pyspark.sql.functions import explode, sequence, to_date, date_format, col, lit, when\n",
    "\n",
    "# Define date and hour range\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2030-12-31\"\n",
    "\n",
    "# Create a DataFrame with a sequence of dates\n",
    "dates_df = spark.sql(f\"\"\"\n",
    "  SELECT sequence(to_date('{start_date}'), to_date('{end_date}'), interval 1 day) as date_seq\n",
    "\"\"\").selectExpr(\"explode(date_seq) as Full_Date\")\n",
    "\n",
    "# Create hour and minute bucket DataFrame\n",
    "hours = spark.range(0, 24).withColumnRenamed(\"id\", \"Hour\")\n",
    "minute_buckets = spark.createDataFrame([(0,), (15,), (30,), (45,)], [\"MinuteBucket\"])\n",
    "\n",
    "# Cross join dates, hours, and minute buckets\n",
    "dim_date_hour_df = dates_df.crossJoin(hours).crossJoin(minute_buckets)\n",
    "\n",
    "# Add Date_Key\n",
    "dim_date_hour_df = dim_date_hour_df.withColumn(\n",
    "    \"Date_Key\", date_format(col(\"Full_Date\"), \"yyyyMMdd\").cast(\"int\")\n",
    ")\n",
    "\n",
    "# IsRushHour: 7-9am and 16-18pm\n",
    "dim_date_hour_df = dim_date_hour_df.withColumn(\n",
    "    \"IsRushHour\",\n",
    "    when(\n",
    "        ((col(\"Hour\").between(7, 9)) | (col(\"Hour\").between(16, 18))),\n",
    "        lit(True)\n",
    "    ).otherwise(lit(False))\n",
    ")\n",
    "\n",
    "# Timeofday: Night (0-5), Morning (6-11), Afternoon (12-17), Evening (18-23)\n",
    "dim_date_hour_df = dim_date_hour_df.withColumn(\n",
    "    \"Timeofday\",\n",
    "    when(col(\"Hour\").between(0, 5), \"Night\")\n",
    "    .when(col(\"Hour\").between(6, 11), \"Morning\")\n",
    "    .when(col(\"Hour\").between(12, 17), \"Afternoon\")\n",
    "    .otherwise(\"Evening\")\n",
    ")\n",
    "\n",
    "# Select and reorder columns\n",
    "dim_date_hour_df = dim_date_hour_df.select(\n",
    "    \"Date_Key\", \"Hour\", \"MinuteBucket\", \"IsRushHour\", \"Timeofday\"\n",
    ")\n",
    "\n",
    "# Create managed table\n",
    "dim_date_hour_df.write.mode(\"overwrite\").saveAsTable(\"divvy.default.DIM_date_hour\")\n",
    "\n",
    "display(dim_date_hour_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10c43f81-2b18-446a-ac1f-8ed7896672f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- PK for dim_date_hour\n",
    "ALTER TABLE divvy.default.DIM_Date_hour\n",
    "ADD CONSTRAINT dim_date_day_pk PRIMARY KEY (Date_Key)\n",
    "NOT ENFORCED;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a14ce24a-5d77-4441-a8fe-93a506d4d76f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DIM Station\n",
    "\n",
    "CREATE TABLE Dim_Station (\n",
    "  Station_Key STRING,\n",
    "  Station_Name STRING,\n",
    "  Latitude_Longitude DOUBLE,\n",
    "  City STRING,\n",
    "  Community_Area STRING,\n",
    "  CONSTRAINT pk_Station_Key PRIMARY KEY (Station_Key)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cd7239e-d715-44ef-92bb-853bdfad7dda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DIM Rider\n",
    "\n",
    "CREATE TABLE Dim_Rider (\n",
    "  Rider_key STRING,\n",
    "  Bike_Type STRING,\n",
    "  CONSTRAINT pk_Rider_key PRIMARY KEY (Rider_key)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c355f46b-8af7-49f1-8eda-94a9c1d73665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DIM Weather\n",
    "\n",
    "CREATE TABLE Dim_Weather(\n",
    "  Weather_Key STRING,\n",
    "  Temp_type_text STRING,\n",
    "  Temp_type_bin DOUBLE,\n",
    "  Humidity_categories_text STRING,\n",
    "  Humidity_categories_bin DOUBLE,\n",
    "  Precipitation_types_text STRING,\n",
    "  Precipitation_types_bin DOUBLE,\n",
    "  Wind_type_categories_text STRING,\n",
    "  Wind_type_categories_bin DOUBLE,\n",
    "  CONSTRAINT pk_Weather_Key PRIMARY KEY (Weather_Key)\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02 - Creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
